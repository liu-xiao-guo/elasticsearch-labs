{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2259f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "from elasticsearch.client import MlClient\n",
    "from eland.ml.pytorch import PyTorchModel\n",
    "from eland.ml.pytorch.transformers import TransformerModel\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcee239f-e2fa-4250-a13c-2a469f99ab51",
   "metadata": {},
   "source": [
    "# Connect to Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "507c0cd3-e26a-410f-aec4-40fd4c6a4e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_user=os.getenv('ES_USER')\n",
    "elastic_password=os.getenv('ES_PASSWORD')\n",
    "elastic_endpoint=os.getenv(\"ES_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7ae4cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'liuxgm.local', 'cluster_name': 'elasticsearch', 'cluster_uuid': 'n1BjmRPcR2GObT6ZMbJ9xA', 'version': {'number': '8.11.0', 'build_flavor': 'default', 'build_type': 'tar', 'build_hash': 'd9ec3fa628c7b0ba3d25692e277ba26814820b20', 'build_date': '2023-11-04T10:04:57.184859352Z', 'build_snapshot': False, 'lucene_version': '9.8.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'}\n"
     ]
    }
   ],
   "source": [
    "url = f\"https://{elastic_user}:{elastic_password}@{elastic_endpoint}:9200\"\n",
    "client = Elasticsearch(url, ca_certs = \"./http_ca.crt\", verify_certs = True)\n",
    " \n",
    "print(client.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd13b9be-02ae-4926-be15-fd419027e27b",
   "metadata": {},
   "source": [
    "# Set the model name from Hugging Face and task type\n",
    "# open ai detector model - developed by open ai https://github.com/openai/gpt-2-output-dataset/tree/master/detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21ddf877-d2a6-4686-994c-90b58f8dc4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base-openai-detector were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "STAGE:2023-12-23 18:11:58 87849:2048871 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "STAGE:2023-12-23 18:11:59 87849:2048871 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2023-12-23 18:11:59 87849:2048871 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/eland/ml/pytorch/_pytorch_model.py:78: ElasticsearchWarning: Your license will expire in [5] days. Contact your administrator or update your license for continued use of features\n",
      "  self._client.ml.put_trained_model(model_id=self.model_id, **config_map)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a8a0a45badb4e3c803e3686661eff62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/476 [00:00<?, ? parts/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/eland/ml/pytorch/_pytorch_model.py:105: ElasticsearchWarning: Your license will expire in [5] days. Contact your administrator or update your license for continued use of features\n",
      "  self._client.ml.put_trained_model_definition_part(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/eland/ml/pytorch/_pytorch_model.py:83: ElasticsearchWarning: Your license will expire in [5] days. Contact your administrator or update your license for continued use of features\n",
      "  self._client.perform_request(\n",
      "/var/folders/kw/pvmj1zgs44l8t32cs8blf6sc0000gn/T/ipykernel_87849/924992814.py:17: ElasticsearchWarning: Your license will expire in [5] days. Contact your administrator or update your license for continued use of features\n",
      "  s = MlClient.start_trained_model_deployment(client, model_id=es_model_id)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'assignment': {'task_parameters': {'model_id': 'roberta-base-openai-detector',\n",
       "   'deployment_id': 'roberta-base-openai-detector',\n",
       "   'model_bytes': 498663888,\n",
       "   'threads_per_allocation': 1,\n",
       "   'number_of_allocations': 1,\n",
       "   'queue_capacity': 1024,\n",
       "   'cache_size': '498663888b',\n",
       "   'priority': 'normal',\n",
       "   'per_deployment_memory_bytes': 498596904,\n",
       "   'per_allocation_memory_bytes': 695458988},\n",
       "  'routing_table': {'L9iKlXXzQgC_jV23VTtmjA': {'current_allocations': 1,\n",
       "    'target_allocations': 1,\n",
       "    'routing_state': 'started',\n",
       "    'reason': ''}},\n",
       "  'assignment_state': 'started',\n",
       "  'start_time': '2023-12-23T10:12:31.863175Z',\n",
       "  'max_assigned_allocations': 1}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_model_id ='roberta-base-openai-detector'\n",
    "tm = TransformerModel(model_id=hf_model_id, task_type=\"text_classification\")\n",
    "\n",
    "#set the modelID as it is named in Elasticsearch\n",
    "es_model_id = tm.elasticsearch_model_id()\n",
    "\n",
    "# Download the model from Hugging Face\n",
    "tmp_path = \"models\"\n",
    "Path(tmp_path).mkdir(parents=True, exist_ok=True)\n",
    "model_path, config, vocab_path = tm.save(tmp_path)\n",
    "\n",
    "# Load the model into Elasticsearch\n",
    "ptm = PyTorchModel(client, es_model_id)\n",
    "ptm.import_model(model_path=model_path, config_path=None, vocab_path=vocab_path, config=config)\n",
    "\n",
    "#Start the model\n",
    "s = MlClient.start_trained_model_deployment(client, model_id=es_model_id)\n",
    "s.body"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d5ae1d-5e2a-4ffa-98a7-239ee2019508",
   "metadata": {},
   "source": [
    "# Set the model name from Hugging Face and task type\n",
    "# sentence-transformers model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9454d87-677e-43d6-9735-4c7294e70129",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-12-23 18:19:10 87849:2048871 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "STAGE:2023-12-23 18:19:10 87849:2048871 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2023-12-23 18:19:10 87849:2048871 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f69eb7cf10de464bbd998c326b9d0132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/416 [00:00<?, ? parts/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kw/pvmj1zgs44l8t32cs8blf6sc0000gn/T/ipykernel_87849/837366150.py:17: ElasticsearchWarning: Your license will expire in [5] days. Contact your administrator or update your license for continued use of features\n",
      "  s = MlClient.start_trained_model_deployment(client, model_id=es_model_id)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'assignment': {'task_parameters': {'model_id': 'sentence-transformers__all-mpnet-base-v2',\n",
       "   'deployment_id': 'sentence-transformers__all-mpnet-base-v2',\n",
       "   'model_bytes': 435655636,\n",
       "   'threads_per_allocation': 1,\n",
       "   'number_of_allocations': 1,\n",
       "   'queue_capacity': 1024,\n",
       "   'cache_size': '435655636b',\n",
       "   'priority': 'normal',\n",
       "   'per_deployment_memory_bytes': 435587600,\n",
       "   'per_allocation_memory_bytes': 757850304},\n",
       "  'routing_table': {'L9iKlXXzQgC_jV23VTtmjA': {'current_allocations': 1,\n",
       "    'target_allocations': 1,\n",
       "    'routing_state': 'started',\n",
       "    'reason': ''}},\n",
       "  'assignment_state': 'started',\n",
       "  'start_time': '2023-12-23T10:19:37.377013Z',\n",
       "  'max_assigned_allocations': 1}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_model_id='sentence-transformers/all-mpnet-base-v2'\n",
    "tm = TransformerModel(model_id=hf_model_id, task_type=\"text_embedding\")\n",
    "\n",
    "#set the modelID as it is named in Elasticsearch\n",
    "es_model_id = tm.elasticsearch_model_id()\n",
    "\n",
    "# Download the model from Hugging Face\n",
    "tmp_path = \"models\"\n",
    "Path(tmp_path).mkdir(parents=True, exist_ok=True)\n",
    "model_path, config, vocab_path = tm.save(tmp_path)\n",
    "\n",
    "# Load the model into Elasticsearch\n",
    "ptm = PyTorchModel(client, es_model_id)\n",
    "ptm.import_model(model_path=model_path, config_path=None, vocab_path=vocab_path, config=config)\n",
    "\n",
    "# Start the model\n",
    "s = MlClient.start_trained_model_deployment(client, model_id=es_model_id)\n",
    "s.body"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b43a415-64d0-4b1a-a358-ad8733c1c478",
   "metadata": {},
   "source": [
    "# source index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f48bc574-97ca-4021-80f6-4c92fce017f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'plagiarism-docs'})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.indices.create(\n",
    "index=\"plagiarism-docs\",\n",
    "mappings= {\n",
    "    \"properties\": {\n",
    "        \"title\": {\n",
    "            \"type\": \"text\",\n",
    "            \"fields\": {\n",
    "                \"keyword\": {\n",
    "                \"type\": \"keyword\"\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"abstract\": {\n",
    "            \"type\": \"text\",\n",
    "            \"fields\": {\n",
    "                \"keyword\": {\n",
    "                \"type\": \"keyword\"\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"url\": {\n",
    "            \"type\": \"keyword\"\n",
    "        },\n",
    "        \"venue\": {\n",
    "            \"type\": \"keyword\"\n",
    "        },\n",
    "         \"year\": {\n",
    "            \"type\": \"keyword\"\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b89834b-a8d0-43dc-9522-cd48d3730048",
   "metadata": {},
   "source": [
    "# ingest pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32bb413d-49d4-4030-9e35-14fc192d4151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.ingest.put_pipeline(\n",
    "    id=\"plagiarism-checker-pipeline\",\n",
    "    processors = [\n",
    "    {\n",
    "      \"inference\": { #for ml models - to infer against the data that is being ingested in the pipeline\n",
    "        \"model_id\": \"roberta-base-openai-detector\", #text classification model id\n",
    "        \"target_field\": \"openai-detector\", # Target field for the inference results\n",
    "        \"field_map\": { #Maps the document field names to the known field names of the model.\n",
    "        \"abstract\": \"text_field\" # Field matching our configured trained model input. Typically for NLP models, the field name is text_field.\n",
    "        }\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"inference\": {\n",
    "        \"model_id\": \"sentence-transformers__all-mpnet-base-v2\", #text embedding model model id\n",
    "        \"target_field\": \"abstract_vector\", # Target field for the inference results\n",
    "        \"field_map\": { #Maps the document field names to the known field names of the model.\n",
    "        \"abstract\": \"text_field\" # Field matching our configured trained model input. Typically for NLP models, the field name is text_field.\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02a6a7b-b90b-4307-a16c-810fdca4ca08",
   "metadata": {},
   "source": [
    "# Create plagiarism checker index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbdf9c46-02e0-4c74-8449-9f82cc494ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'plagiarism-checker'})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.indices.create(\n",
    "index=\"plagiarism-checker\",\n",
    "mappings={\n",
    "\"properties\": {\n",
    "    \"title\": {\n",
    "        \"type\": \"text\",\n",
    "        \"fields\": {\n",
    "            \"keyword\": {\n",
    "                \"type\": \"keyword\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"abstract\": {\n",
    "        \"type\": \"text\",\n",
    "        \"fields\": {\n",
    "            \"keyword\": {\n",
    "                \"type\": \"keyword\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"url\": {\n",
    "        \"type\": \"keyword\"\n",
    "    },\n",
    "    \"venue\": {\n",
    "        \"type\": \"keyword\"\n",
    "    },\n",
    "    \"year\": {\n",
    "        \"type\": \"keyword\"\n",
    "    },\n",
    "    \"abstract_vector.predicted_value\": { # Inference results field, target_field.predicted_value\n",
    "    \"type\": \"dense_vector\",\n",
    "    \"dims\": 768, # embedding_size\n",
    "    \"index\": \"true\",\n",
    "    \"similarity\": \"dot_product\" #  When indexing vectors for approximate kNN search, you need to specify the similarity function for comparing the vectors.\n",
    "         }\n",
    "  }\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc6a4e9-2f3e-49c3-8d62-49242e312e02",
   "metadata": {},
   "source": [
    "# Write source documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4413d6da-9c15-43b5-a092-90a7e71b97b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 974 documents\n",
      "Done indexing documents into `plagiarism-docs` source index\n"
     ]
    }
   ],
   "source": [
    "# Load data into a JSON object\n",
    "with open('emnlp2016-2018.json') as f:\n",
    "   data_json = json.load(f)\n",
    " \n",
    "print(f\"Successfully loaded {len(data_json)} documents\")\n",
    "\n",
    "def create_index_body(doc):\n",
    "    \"\"\" Generate the body for an Elasticsearch document. \"\"\"\n",
    "    return {\n",
    "        \"_index\": \"plagiarism-docs\",\n",
    "        \"_source\": doc,\n",
    "    }\n",
    "\n",
    "# Prepare the documents to be indexed\n",
    "documents = [create_index_body(doc) for doc in data_json]\n",
    "\n",
    "# Use helpers.bulk to index\n",
    "helpers.bulk(client, documents)\n",
    "\n",
    "print(\"Done indexing documents into `plagiarism-docs` source index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb818d42-3bde-4438-8651-abd6da3c1671",
   "metadata": {},
   "source": [
    "# Reindex with ingest pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050562b0-9d18-48a0-88fa-ae22f96ef4d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82665f10-0fc6-40ac-873c-5289ad0025fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'task': 'L9iKlXXzQgC_jV23VTtmjA:1053110'})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.reindex(wait_for_completion=False,\n",
    "               source={\n",
    "                  \"index\": \"plagiarism-docs\"\n",
    "    },\n",
    "               dest= {\n",
    "                  \"index\": \"plagiarism-checker\",\n",
    "                  \"pipeline\": \"plagiarism-checker-pipeline\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be9570a-98dd-404d-a91c-c0e2479b83c7",
   "metadata": {},
   "source": [
    "# duplicated text - direct plagiarism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e8df6cc-5a60-4c1f-aff9-66c365076bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Moderate similarity detected.\n",
      "\n",
      "Most similar document: 'Natural Language Comprehension with the EpiReader'\n",
      "\n",
      "Abstract: We present the EpiReader, a novel model for machine comprehension of text. Machine comprehension of unstructured, real-world text is a major research goal for natural language processing. Current tests of machine comprehension pose questions whose answers can be inferred from some supporting text, and evaluate a model's response to the questions. The EpiReader is an end-to-end neural model comprising two components: the first component proposes a small set of candidate answers after comparing a question to its supporting text, and the second component formulates hypotheses using the proposed candidates and the question, then reranks the hypotheses based on their estimated concordance with the supporting text. We present experiments demonstrating that the EpiReader sets a new state-of-the-art on the CNN and Children's Book Test machine comprehension benchmarks, outperforming previous neural models by a significant margin.\n",
      "\n",
      "url: http://aclweb.org/anthology/D16-1013\n",
      "\n",
      "Score:0.8345975\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kw/pvmj1zgs44l8t32cs8blf6sc0000gn/T/ipykernel_87849/283995233.py:54: ElasticsearchWarning: Your license will expire in [5] days. Contact your administrator or update your license for continued use of features\n",
      "  ml_response = ml_client.infer_trained_model(model_id=model_id, docs=document)\n"
     ]
    }
   ],
   "source": [
    "model_text = 'Understanding and reasoning about cooking recipes is a fruitful research direction towards enabling machines to interpret procedural text. In this work, we introduce RecipeQA, a dataset for multimodal comprehension of cooking recipes. It comprises of approximately 20K instructional recipes with multiple modalities such as titles, descriptions and aligned set of images. With over 36K automatically generated question-answer pairs, we design a set of comprehension and reasoning tasks that require joint understanding of images and text, capturing the temporal flow of events and making sense of procedural knowledge. Our preliminary results indicate that RecipeQA will serve as a challenging test bed and an ideal benchmark for evaluating machine comprehension systems. The data and leaderboard are available at http://hucvl.github.io/recipeqa.'\n",
    "\n",
    "response = client.search(index='plagiarism-checker', size=1,\n",
    "    knn={\n",
    "        \"field\": \"abstract_vector.predicted_value\",\n",
    "        \"k\": 9,\n",
    "        \"num_candidates\": 974,\n",
    "        \"query_vector_builder\": {\n",
    "            \"text_embedding\": {\n",
    "                \"model_id\": \"sentence-transformers__all-mpnet-base-v2\",\n",
    "                \"model_text\": model_text\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "for hit in response['hits']['hits']:\n",
    "    score = hit['_score']\n",
    "    title = hit['_source']['title']\n",
    "    abstract = hit['_source']['abstract']\n",
    "    openai = hit['_source']['openai-detector']['predicted_value']\n",
    "    url = hit['_source']['url']\n",
    "\n",
    "    if score > 0.9:\n",
    "        print(f\"\\nHigh similarity detected! This might be plagiarism.\")\n",
    "        print(f\"\\nMost similar document: '{title}'\\n\\nAbstract: {abstract}\\n\\nurl: {url}\\n\\nScore:{score}\\n\")\n",
    "\n",
    "        if openai == 'Fake':\n",
    "            print(\"This document may have been created by AI.\\n\")\n",
    "\n",
    "    elif score < 0.7:\n",
    "        print(f\"\\nLow similarity detected. This might not be plagiarism.\")\n",
    "\n",
    "        if openai == 'Fake':\n",
    "            print(\"This document may have been created by AI.\\n\")\n",
    "\n",
    "    else:\n",
    "        print(f\"\\nModerate similarity detected.\")\n",
    "        print(f\"\\nMost similar document: '{title}'\\n\\nAbstract: {abstract}\\n\\nurl: {url}\\n\\nScore:{score}\\n\")\n",
    "\n",
    "        if openai == 'Fake':\n",
    "            print(\"This document may have been created by AI.\\n\")\n",
    "\n",
    "ml_client = MlClient(client)\n",
    "\n",
    "model_id = 'roberta-base-openai-detector' #open ai text classification model\n",
    "\n",
    "document = [\n",
    "    {\n",
    "        \"text_field\": model_text\n",
    "    }\n",
    "]\n",
    "\n",
    "ml_response = ml_client.infer_trained_model(model_id=model_id, docs=document)\n",
    "\n",
    "predicted_value = ml_response['inference_results'][0]['predicted_value']\n",
    "\n",
    "if predicted_value == 'Fake':\n",
    "    print(\"Note: The text query you entered may have been generated by AI.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c267fae8-5733-4026-b15f-74d286dce9b9",
   "metadata": {},
   "source": [
    "# similar text - paraphrase plagiarism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d06305de-725a-499b-b3dc-a5958d68de82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Moderate similarity detected.\n",
      "\n",
      "Most similar document: 'Sort Story: Sorting Jumbled Images and Captions into Stories'\n",
      "\n",
      "Abstract: Temporal common sense has applications in AI tasks such as QA, multi-document summarization, and human-AI communication. We propose the task of sequencing -- given a jumbled set of aligned image-caption pairs that belong to a story, the task is to sort them such that the output sequence forms a coherent story. We present multiple approaches, via unary (position) and pairwise (order) predictions, and their ensemble-based combinations, achieving strong results on this task. We use both text-based and image-based features, which depict complementary improvements. Using qualitative examples, we demonstrate that our models have learnt interesting aspects of temporal common sense.\n",
      "\n",
      "url: http://aclweb.org/anthology/D16-1091\n",
      "\n",
      "Score:0.7819495\n",
      "\n",
      "Note: The text query you entered may have been generated by AI.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kw/pvmj1zgs44l8t32cs8blf6sc0000gn/T/ipykernel_87849/4098368190.py:54: ElasticsearchWarning: Your license will expire in [5] days. Contact your administrator or update your license for continued use of features\n",
      "  ml_response = ml_client.infer_trained_model(model_id=model_id, docs=document)\n"
     ]
    }
   ],
   "source": [
    "model_text = 'Comprehending and deducing information from culinary instructions represents a promising avenue for research aimed at empowering artificial intelligence to decipher step-by-step text. In this study, we present CuisineInquiry, a database for the multifaceted understanding of cooking guidelines. It encompasses a substantial number of informative recipes featuring various elements such as headings, explanations, and a matched assortment of visuals. Utilizing an extensive set of automatically crafted question-answer pairings, we formulate a series of tasks focusing on understanding and logic that necessitate a combined interpretation of visuals and written content. This involves capturing the sequential progression of events and extracting meaning from procedural expertise. Our initial findings suggest that CuisineInquiry is poised to function as a demanding experimental platform.'\n",
    "\n",
    "response = client.search(index='plagiarism-checker', size=1,\n",
    "    knn={\n",
    "        \"field\": \"abstract_vector.predicted_value\",\n",
    "        \"k\": 9,\n",
    "        \"num_candidates\": 974,\n",
    "        \"query_vector_builder\": {\n",
    "            \"text_embedding\": {\n",
    "                \"model_id\": \"sentence-transformers__all-mpnet-base-v2\",\n",
    "                \"model_text\": model_text\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "for hit in response['hits']['hits']:\n",
    "    score = hit['_score']\n",
    "    title = hit['_source']['title']\n",
    "    abstract = hit['_source']['abstract']\n",
    "    openai = hit['_source']['openai-detector']['predicted_value']\n",
    "    url = hit['_source']['url']\n",
    "\n",
    "    if score > 0.9:\n",
    "        print(f\"\\nHigh similarity detected! This might be plagiarism.\")\n",
    "        print(f\"\\nMost similar document: '{title}'\\n\\nAbstract: {abstract}\\n\\nurl: {url}\\n\\nScore:{score}\\n\")\n",
    "\n",
    "        if openai == 'Fake':\n",
    "            print(\"This document may have been created by AI.\\n\")\n",
    "\n",
    "    elif score < 0.7:\n",
    "        print(f\"\\nLow similarity detected. This might not be plagiarism.\")\n",
    "\n",
    "        if openai == 'Fake':\n",
    "            print(\"This document may have been created by AI.\\n\")\n",
    "\n",
    "    else:\n",
    "        print(f\"\\nModerate similarity detected.\")\n",
    "        print(f\"\\nMost similar document: '{title}'\\n\\nAbstract: {abstract}\\n\\nurl: {url}\\n\\nScore:{score}\\n\")\n",
    "\n",
    "        if openai == 'Fake':\n",
    "            print(\"This document may have been created by AI.\\n\")\n",
    "\n",
    "ml_client = MlClient(client)\n",
    "\n",
    "model_id = 'roberta-base-openai-detector' #open ai text classification model\n",
    "\n",
    "document = [\n",
    "    {\n",
    "        \"text_field\": model_text\n",
    "    }\n",
    "]\n",
    "\n",
    "ml_response = ml_client.infer_trained_model(model_id=model_id, docs=document)\n",
    "\n",
    "predicted_value = ml_response['inference_results'][0]['predicted_value']\n",
    "\n",
    "if predicted_value == 'Fake':\n",
    "    print(\"Note: The text query you entered may have been generated by AI.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e196f300-9560-49ab-bb72-520e133f53d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_3.11",
   "language": "python",
   "name": "python_3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
