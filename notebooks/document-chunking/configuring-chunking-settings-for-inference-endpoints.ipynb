{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a765629",
   "metadata": {},
   "source": [
    "# Configuring Chunking Settings For Inference Endpoints\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/elastic/elasticsearch-labs/blob/main/notebooks/document-chunking/configuring-chunking-settings-for-inference-endpoints.ipynb)\n",
    "\n",
    "\n",
    "Learn how to configure [chunking settings](https://www.elastic.co/guide/en/elasticsearch/reference/current/inference-apis.html#infer-chunking-config) for [Inference API](https://www.elastic.co/guide/en/elasticsearch/reference/current/inference-apis.html) endpoints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9101eb9",
   "metadata": {},
   "source": [
    "# ðŸ§° Requirements\n",
    "\n",
    "For this example, you will need:\n",
    "\n",
    "- An Elastic deployment:\n",
    "\n",
    "- Elasticsearch 8.16 or above.\n",
    "\n",
    "- Python 3.7 or above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd69cc0",
   "metadata": {},
   "source": [
    "# Create Elastic Cloud deployment or serverless project\n",
    "\n",
    "If you don't have an Elastic Cloud deployment, sign up [here](https://cloud.elastic.co/registration?utm_source=github&utm_content=elasticsearch-labs-notebook) for a free trial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27dffbf",
   "metadata": {},
   "source": [
    "# Install packages and connect with Elasticsearch Client\n",
    "\n",
    "To get started, we'll need to connect to our Elastic deployment using the Python client (version 8.12.0 or above).\n",
    "Because we're using an Elastic Cloud deployment, we'll use the **Cloud ID** to identify our deployment.\n",
    "\n",
    "First we need to `pip` install the following packages:\n",
    "\n",
    "- `elasticsearch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c4b16bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: elasticsearch in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (8.17.1)\n",
      "Requirement already satisfied: elastic-transport<9,>=8.15.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from elasticsearch) (8.17.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (2.2.1)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ef96b3",
   "metadata": {},
   "source": [
    "Next, we need to import the modules we need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "690ff9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fa2b6c",
   "metadata": {},
   "source": [
    "Now we can instantiate the Python Elasticsearch client.\n",
    "\n",
    "Then we create a `client` object that instantiates an instance of the `Elasticsearch` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "195cc597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'liuxgn.local', 'cluster_name': 'elasticsearch', 'cluster_uuid': 'h66jNmrlQoGZ0j1RdU0j8Q', 'version': {'number': '8.17.2', 'build_flavor': 'default', 'build_type': 'tar', 'build_hash': '747663ddda3421467150de0e4301e8d4bc636b0c', 'build_date': '2025-02-05T22:10:57.067596412Z', 'build_snapshot': False, 'lucene_version': '9.12.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'}\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "ES_USER= os.getenv(\"ES_USER\")\n",
    "ES_PASSWORD = os.getenv(\"ES_PASSWORD\")\n",
    "ES_ENDPOINT = os.getenv(\"ES_ENDPOINT\")\n",
    "\n",
    "url = f\"https://{ES_USER}:{ES_PASSWORD}@{ES_ENDPOINT}:9200\"\n",
    "client = Elasticsearch(url, ca_certs = \"./http_ca.crt\", verify_certs = True)\n",
    "\n",
    "print(es.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659c5890",
   "metadata": {},
   "source": [
    "Refer to [the documentation](https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/connecting.html#connect-self-managed-new) to learn how to connect to a self-managed deployment.\n",
    "\n",
    "Read [this page](https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/connecting.html#connect-self-managed-new) to learn how to connect using API keys."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840d92f0",
   "metadata": {},
   "source": [
    "<a name=\"create-the-inference-endpoint\"></a>\n",
    "## Create the inference endpoint object\n",
    "\n",
    "Let's create the inference endpoint by using the [Create Inference API](https://www.elastic.co/guide/en/elasticsearch/reference/current/put-inference-api.html#put-inference-api-desc).\n",
    "\n",
    "In this example, you'll be creating an inference endpoint for the [ELSER integration](https://www.elastic.co/guide/en/elasticsearch/reference/current/infer-service-elser.html) which will deploy Elastic's [ELSER model](https://www.elastic.co/guide/en/machine-learning/current/ml-nlp-elser.html) within your cluster. Chunking settings are configurable for any inference endpoint with an embedding task type. A full list of available integrations can be found in the [Create Inference API](https://www.elastic.co/guide/en/elasticsearch/reference/current/put-inference-api.html#put-inference-api-desc) documentation.\n",
    "\n",
    "To configure chunking settings, the request body must contain a `chunking_settings` map with a `strategy` value along with any required values for the selected chunking strategy. For this example, you'll be configuring chunking settings for a `sentence` strategy with a maximum chunk size of 25 words and 1 sentence overlap between chunks. For more information on available chunking strategies and their configurable values, see the [chunking strategies documentation](https://www.elastic.co/guide/en/elasticsearch/reference/current/inference-apis.html#_chunking_strategies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d007737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "try: \n",
    "    client.inference.put(\n",
    "        task_type=\"sparse_embedding\",\n",
    "        inference_id=\"my_elser_endpoint\",\n",
    "        body={\n",
    "            \"service\": \"elasticsearch\",\n",
    "            \"service_settings\": {\n",
    "                \"num_allocations\": 1,\n",
    "                \"num_threads\": 1,\n",
    "                \"model_id\": \".elser_model_2\",\n",
    "            },\n",
    "            \"chunking_settings\": {\n",
    "                \"strategy\": \"sentence\",\n",
    "                \"max_chunk_size\": 25,\n",
    "                \"sentence_overlap\": 1,\n",
    "            },\n",
    "        },\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01de885",
   "metadata": {},
   "source": [
    "<a name=\"create-the-index\"></a>\n",
    "## Create the index\n",
    "\n",
    "To see the chunking settings you've configured in action, you'll need to ingest a document into a semantic text field of an index. Let's create an index with a semantic text field linked to the inference endpoint created in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0eed3e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'my_index'})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.indices.create(\n",
    "    index=\"my_index\",\n",
    "    mappings={\n",
    "        \"properties\": {\n",
    "            \"infer_field\": {\n",
    "                \"type\": \"semantic_text\",\n",
    "                \"inference_id\": \"my_elser_endpoint\",\n",
    "            }\n",
    "        }\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ae72e4",
   "metadata": {},
   "source": [
    "<a name=\"ingest-a-document\"></a>\n",
    "## Ingest a document\n",
    "\n",
    "Now let's ingest a document into the index created in the previous step.\n",
    "\n",
    "Note: It may take some time Elasticsearch to allocate nodes to the ELSER model deployment that is started when creating the inference endpoint. You will need to wait until the deployment is allocated to a node before the request below can succeed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8ecaec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'_index': 'my_index', '_id': '2sV9opUBC2KzDRIIguGZ', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 0, '_primary_term': 1})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.index(\n",
    "    index=\"my_index\",\n",
    "    document={\n",
    "        \"infer_field\": \"This is some sample document data. The data is being used to demonstrate the configurable chunking settings feature. The configured chunking settings will determine how this text is broken down into chunks to help increase inference accuracy.\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc7ca3a",
   "metadata": {},
   "source": [
    "<a name=\"view-the-chunks\"></a>\n",
    "## View the chunks\n",
    "\n",
    "The generated chunks and their corresponding inference results can be seen stored in the document in the index under the key `chunks` within the `_inference_fields` metafield. The chunks are stored as a list of character offset values. Let's see the chunks generated when ingesting the documenting in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58dc9019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'took': 1, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 1, 'relation': 'eq'}, 'max_score': 1.0, 'hits': [{'_index': 'my_index', '_id': '2sV9opUBC2KzDRIIguGZ', '_score': 1.0, '_source': {'infer_field': {'text': 'This is some sample document data. The data is being used to demonstrate the configurable chunking settings feature. The configured chunking settings will determine how this text is broken down into chunks to help increase inference accuracy.', 'inference': {'inference_id': 'my_elser_endpoint', 'model_settings': {'task_type': 'sparse_embedding'}, 'chunks': [{'text': 'This is some sample document data. The data is being used to demonstrate the configurable chunking settings feature. ', 'embeddings': {'chunk': 2.4421947, 'sample': 1.7515649, 'document': 1.7087852, 'data': 1.5663441, 'lump': 1.3600641, 'feature': 1.2773305, 'settings': 1.2596056, '##gur': 1.2498505, 'demonstrate': 1.1914899, '##ing': 1.1849855, 'demonstration': 1.1815082, '##fi': 1.0912751, 'configuration': 1.0769424, 'setting': 1.0405105, 'samples': 0.9957234, 'doc': 0.92119396, 'used': 0.86591834, 'file': 0.8023139, 'picture': 0.7648303, '##able': 0.7383928, 'block': 0.73488367, 'image': 0.72795314, 'group': 0.713384, 'keyboard': 0.6967799, 'demonstrating': 0.6938972, 'custom': 0.6846669, 'rope': 0.6731889, 'this': 0.6409621, 'show': 0.63992727, 'interface': 0.6064495, 'cad': 0.6057748, 'archive': 0.60196495, 'documents': 0.5953074, 'display': 0.58809495, 'apache': 0.5857421, 'illustrate': 0.5801775, 'layout': 0.572818, 'editor': 0.56998426, 'algorithm': 0.5684865, 'mouse': 0.5499693, 'button': 0.54322284, 'client': 0.53316766, 'cluster': 0.532416, 'server': 0.5279873, 'sid': 0.52444947, 'protocol': 0.5222285, 'java': 0.5218285, 'zoom': 0.5188114, 'network': 0.5147043, 'proof': 0.50381196, 'deployment': 0.49420977, 'software': 0.49279866, 'below': 0.4886513, 'bot': 0.48791316, 'bulk': 0.48084596, 'some': 0.46057677, 'routing': 0.4481885, 'example': 0.44674018, 'useful': 0.44116965, 'buffer': 0.432626, 'chunks': 0.43182218, 'information': 0.42709377, 'test': 0.4250754, 'demonstrated': 0.42388535, 'sorting': 0.4203345, 'database': 0.41148514, 'evidence': 0.37005615, 'tool': 0.37001002, 'tray': 0.36609098, 'paper': 0.3652286, 'prototype': 0.3622308, 'table': 0.3463312, 'video': 0.3453483, 'camera': 0.34407586, 'compression': 0.34229487, 'lane': 0.33556053, 'chip': 0.33086133, 'chart': 0.30637485, 'layer': 0.30630156, 'script': 0.30522367, 'cube': 0.29447332, 'sheet': 0.2928881, 'stuffing': 0.29146144, 'graphic': 0.28413638, 'above': 0.2835977, 'is': 0.28336257, 'tutor': 0.27594057, 'explain': 0.2721791, 'explore': 0.25859076, 'setup': 0.25443703, 'mp': 0.24311014, 'excel': 0.24143381, 'features': 0.23968564, 'specify': 0.23386544, 'control': 0.23218468, 'font': 0.21796037, 'mode': 0.21660309, 'web': 0.21374878, 'texture': 0.21142787, 'diagram': 0.19513266, 'playback': 0.19337349, 'pattern': 0.19078293, 'technique': 0.18588427, 'tam': 0.18585536, 'wireless': 0.1855329, 'management': 0.17931509, 'inventory': 0.17592068, 'serial': 0.16828701, 'storage': 0.16082312, 'chess': 0.14903331, 'beam': 0.14396717, 'source': 0.14310838, 'html': 0.14059862, 'code': 0.13905357, 'format': 0.13301529, 'matrix': 0.13244939, 'symbol': 0.13038254, 'xml': 0.12697688, 'model': 0.12100148, 'notebook': 0.11825277, 'report': 0.11299368, 'machine': 0.11288401, 'user': 0.109410316, 'batch': 0.108262256, 'tab': 0.10807931, 'con': 0.10206202, 'memory': 0.09816152, 'maker': 0.08616668, 'here': 0.08435139, 'wheel': 0.08429551, 'bug': 0.081886075, 'mini': 0.074811235, 'computer': 0.0684936, 'sequence': 0.0679178, 'manager': 0.06274447, 'option': 0.061621442, 'embedded': 0.057095867, 'scene': 0.049471762, 'index': 0.047651645, 'stack': 0.04695568, 'provided': 0.044648055, 'application': 0.041259367, 'api': 0.038209867, 'version': 0.037102815, 'gage': 0.032168135, 'link': 0.02764137, 'platform': 0.0242175, 'processing': 0.020100938, 'download': 0.018251803, '##u': 0.015319186, '##e': 0.011529365, 'slice': 0.0012629399, 'weaving': 0.0007157148, 'implement': 1.9192512e-05}}, {'text': ' The data is being used to demonstrate the configurable chunking settings feature. The configured chunking settings will determine how this text is broken down into', 'embeddings': {'chunk': 2.3900986, 'data': 1.4478004, 'lump': 1.3839706, 'text': 1.3683708, 'demonstrate': 1.2507759, 'feature': 1.2408351, 'demonstration': 1.2253375, '##ing': 1.2112257, 'settings': 1.2036818, 'broken': 1.2011127, '##gur': 1.1775701, 'configured': 1.0721444, 'configuration': 1.0460585, 'setting': 0.99956906, '##fi': 0.9374865, 'down': 0.92171687, 'used': 0.8912679, 'editor': 0.8268482, 'determine': 0.8076769, 'into': 0.75332516, 'break': 0.7488943, '##able': 0.74623954, 'java': 0.7307221, 'custom': 0.72566515, 'demonstrating': 0.7186915, 'display': 0.7070233, 'keyboard': 0.6285119, 'illustrate': 0.60791165, 'demonstrated': 0.6030158, 'layout': 0.58849955, 'show': 0.58740973, 'bot': 0.58533174, 'split': 0.5815678, 'tab': 0.57882965, 'block': 0.5742494, 'algorithm': 0.5460116, 'sid': 0.5381855, 'font': 0.5356039, 'chunks': 0.5219985, 'determined': 0.5182476, 'breakdown': 0.48575574, 'format': 0.47465768, 'group': 0.461058, 'document': 0.437114, 'below': 0.4209222, 'deployment': 0.40211266, 'button': 0.39902756, 'html': 0.3833231, 'syntax': 0.37249792, 'compression': 0.3541742, 'script': 0.34489775, 'file': 0.3327327, 'excel': 0.32160836, 'table': 0.31838065, 'interface': 0.31290743, 'layer': 0.30425876, 'column': 0.2940436, 'control': 0.29113138, 'content': 0.28158334, 'playback': 0.27778214, 'zoom': 0.27726224, 'con': 0.2724906, 'graphic': 0.2695497, 'archive': 0.26923436, 'page': 0.26838484, 'features': 0.26139376, 'proof': 0.2599613, 'cluster': 0.25839937, 'useful': 0.25005832, 'sheet': 0.24645224, 'above': 0.24494977, 'pattern': 0.24167725, 'mode': 0.22142394, 'tool': 0.22018929, 'setup': 0.21856287, 'section': 0.2147411, 'server': 0.21186121, 'bulk': 0.20662925, 'this': 0.20534872, 'test': 0.20314345, 'sort': 0.20228048, 'implement': 0.1925445, 'software': 0.18747908, 'oversee': 0.17458366, 'option': 0.17447925, 'explain': 0.17202842, 'link': 0.1701556, 'embedded': 0.168272, 'profile': 0.16558723, 'buffer': 0.1549949, 'cipher': 0.15109399, 'read': 0.15099518, 'rope': 0.14786498, 'folded': 0.13442756, 'divide': 0.12188083, 'cad': 0.121254414, 'video': 0.119930945, 'texture': 0.11947977, 'xml': 0.11929865, 'slice': 0.11485808, 'database': 0.10903444, 'default': 0.10415338, 'protocol': 0.10169683, 'divided': 0.09877222, 'explore': 0.098743275, 'links': 0.09471474, 'mouse': 0.09304276, 'select': 0.08845226, 'wheel': 0.08787616, 'provided': 0.08438952, 'spelling': 0.083460554, 'example': 0.07533763, 'will': 0.064209945, 'specify': 0.06331485, 'mp': 0.05766554, 'chart': 0.055077504, 'technique': 0.054574084, 'network': 0.05305427, 'web': 0.05068194, 'information': 0.05031574, 'apache': 0.047878943, 'tutor': 0.045190454, 'handling': 0.04245061, 'picture': 0.03695922, 'tempo': 0.03673253, 'error': 0.03209356, 'bug': 0.028451946, 'merge': 0.025473135, 'serial': 0.021897327, 'client': 0.021858606, 'user': 0.02056946, 'prototype': 0.0170173, 'chess': 0.010055361, 'sample': 0.007861152, 'separate': 0.005510853, 'sequence': 0.004765937, 'par': 0.002922314}}, {'text': ' configured chunking settings will determine how this text is broken down into chunks to help increase inference accuracy.', 'embeddings': {'chunk': 2.3509183, 'inference': 1.6927269, 'text': 1.5436834, 'lump': 1.5104471, 'chunks': 1.4967964, 'accuracy': 1.3117697, 'settings': 1.2475933, 'configuration': 1.2474729, 'configured': 1.1941242, '##ing': 1.1319425, 'predict': 1.1048597, 'setting': 1.1033221, 'broken': 1.0827338, 'algorithm': 1.0013249, 'improve': 0.938527, 'precision': 0.8241245, 'guess': 0.8013126, 'down': 0.8003023, 'java': 0.76460797, 'determine': 0.75764024, 'editor': 0.7290859, 'block': 0.72522825, 'gage': 0.71434075, 'enhance': 0.71224385, 'computation': 0.6689893, 'help': 0.6499681, 'analysis': 0.63667387, 'default': 0.6347552, 'custom': 0.63444334, 'break': 0.6299269, 'document': 0.6275418, 'determined': 0.6146929, 'useful': 0.61314183, 'math': 0.6093727, 'reading': 0.6092227, 'pieces': 0.5929545, 'increase': 0.59105146, 'mode': 0.5824351, 'tab': 0.56778866, 'into': 0.54360753, 'breakdown': 0.54068315, 'important': 0.5378407, 'format': 0.5231669, 'split': 0.52302885, 'brain': 0.49355268, 'layout': 0.49197012, 'accurate': 0.48971048, 'content': 0.48141906, 'option': 0.48069486, 'interpretation': 0.4740743, 'software': 0.4611557, 'control': 0.45337632, 'compression': 0.45262825, 'anal': 0.45100054, 'select': 0.42996806, 'chess': 0.4296984, 'technique': 0.4274126, 'ass': 0.42143908, 'regression': 0.41576087, 'conclusion': 0.4115036, 'sequence': 0.41143838, 'exam': 0.41045007, 'memory': 0.40890482, 'plot': 0.4013128, 'tool': 0.39972335, 'better': 0.3849457, 'bot': 0.38018256, 'cube': 0.36391306, 'table': 0.36285615, 'syntax': 0.35994896, 'blocks': 0.35637367, 'tree': 0.3499032, 'slice': 0.34849456, 'processing': 0.34621114, 'sample': 0.3461531, 'learning': 0.33732393, 'cipher': 0.33687624, 'read': 0.33538383, 'data': 0.33377, 'bulk': 0.32757956, 'bug': 0.32280886, 'confidence': 0.31583142, 'spelling': 0.3133908, 'string': 0.3073022, 'font': 0.30359787, 'buffer': 0.2949593, 'html': 0.29227972, 'advantage': 0.2829408, 'group': 0.279814, '##imi': 0.27826005, 'optimal': 0.27203524, 'pattern': 0.26984546, 'button': 0.25518864, 'analyze': 0.2550973, 'tutor': 0.25442058, 'behavior': 0.25332457, 'chart': 0.25219977, 'ability': 0.24495284, 'oversee': 0.24084803, 'preference': 0.24000208, 'protocol': 0.23782681, 'assumption': 0.23647676, 'piece': 0.23308353, 'file': 0.23176828, 'study': 0.22661947, 'cluster': 0.22294068, 'bits': 0.22194235, 'junk': 0.22129372, 'assessment': 0.22117351, 'interpret': 0.22018392, 'limp': 0.21967226, 'interface': 0.21514983, 'cad': 0.2084429, 'rope': 0.20353284, 'feature': 0.2004596, 'forensic': 0.20040067, 'will': 0.19628401, 'keyboard': 0.19131836, 'specify': 0.18848337, 'reduce': 0.18591, 'profile': 0.18590021, 'divided': 0.18574806, 'encoding': 0.17314652, 'quality': 0.17247356, 'index': 0.16778053, 'sort': 0.16384123, 'fragments': 0.16067807, 'effect': 0.16010517, 'chance': 0.15893792, 'this': 0.15849862, 'display': 0.15779202, 'sid': 0.15746292, 'regulation': 0.15485615, 'par': 0.15096638, '##s': 0.14889249, 'setup': 0.14764738, 'extraction': 0.1461035, 'cue': 0.14485513, 'divide': 0.1443806, 'texture': 0.14253813, 'audio': 0.14057212, 'zoom': 0.14056373, 'node': 0.13749303, 'excel': 0.13212636, 'segments': 0.130735, 'server': 0.12851469, 'decision': 0.12592974, 'selection': 0.12076602, 'fragmented': 0.1185424, 'notebook': 0.11448892, 'speech': 0.11253265, 'conclusions': 0.11127597, 'thick': 0.11015984, 'consistency': 0.10959911, 'notation': 0.10924768, 'assist': 0.10496094, 'tempo': 0.0998063, 'disadvantage': 0.09751628, 'xml': 0.09658352, 'adjust': 0.096468136, 'boost': 0.096387275, 'managed': 0.09455879, 'script': 0.0943488, 'network': 0.093009636, 'modification': 0.09233954, 'log': 0.08897719, 'texts': 0.084418446, 'best': 0.08152618, 'speed': 0.07798642, 'performance': 0.07292788, 'spatial': 0.07188669, 'material': 0.069600925, 'affect': 0.06633092, 'estimation': 0.06433359, 'class': 0.060007237, 'graphic': 0.05691221, 'how': 0.055564888, 'optimization': 0.048652623, 'platform': 0.04444602, 'evidence': 0.04430393, 'determination': 0.04402403, '##ed': 0.042957887, 'archive': 0.040793803, 'length': 0.040468846, 'checkpoint': 0.040067047, 'sha': 0.038721018, 'column': 0.037760213, 'representation': 0.036928546, 'sharpe': 0.03636923, 'management': 0.03441683, 'segment': 0.033719078, 'is': 0.030220572, 'structure': 0.030061295, 'regulate': 0.029767659, 'practice': 0.026774663, 'scribe': 0.023487326, 'deployment': 0.023069445, 'division': 0.018499926, 'separated': 0.017154295, 'mask': 0.011205952, 'mat': 0.007828626, 'sequencing': 0.006469615, 'preferences': 0.0057697417, '##cing': 0.0014488924, 'method': 0.00094393035, 'observation': 4.2199197e-05}}]}}}}]}})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.search(\n",
    "    index=\"my_index\",\n",
    "    body={\"size\": 100, \"query\": {\"match_all\": {}}, \"fields\": [\"_inference_fields\"]},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193f5b8d",
   "metadata": {},
   "source": [
    "<a name=\"conclusion\"></a>\n",
    "## Conclusion\n",
    "\n",
    "You've now learned how to configure chunking settings for an inference endpoint! For more information about configurable chunking, see the [configuring chunking](https://www.elastic.co/guide/en/elasticsearch/reference/current/inference-apis.html#infer-chunking-config) documentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
